{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "signal-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-mississippi",
   "metadata": {},
   "source": [
    "# TIPS\n",
    "1. Delete everything inside a bracket first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "searching-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "textfile = \"data/set4/a7.txt\"\n",
    "\n",
    "sentence1 = \"Harry Potter and the Prisoner of Azkaban is a 2004 fantasy film directed by Alfonso Cuarón and distributed by Warner Bros.\"\n",
    "sentence2 = \"Harry Potter has been spending another unhappy summer with the Dursleys.\"\n",
    "sentence3 = \"The Prisoner of Azkaban made a total of $796.7 million worldwide\"\n",
    "sentence4 = \"The film took them 13.47 million dollars.\"\n",
    "\n",
    "\n",
    "doc1 = nlp(sentence1)\n",
    "doc2 = nlp(sentence2)\n",
    "doc3 = nlp(sentence3)\n",
    "doc4 = nlp(sentence4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "painful-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = \"data/set4/a7.txt\"\n",
    "\n",
    "def get_text(textfile):\n",
    "    #put entire text file into a list of sentences\n",
    "    text = []\n",
    "    with open(textfile, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.split('. ')\n",
    "            if len(line) != 0:\n",
    "                temp = line[0].strip('\\n')\n",
    "                if len(temp) != 0:\n",
    "                    text.append(temp)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prerequisite-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile1 = \"data/set4/a1.txt\"\n",
    "textfile2 = \"data/set4/a7.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "removable-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_artist, text_hp = get_text(textfile1), get_text(textfile2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-script",
   "metadata": {},
   "source": [
    "# POS tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "professional-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_lst(text):\n",
    "    #list of sentences\n",
    "    POS_tag_dict = dict()\n",
    "    for i,line in enumerate(text):\n",
    "        tags = []\n",
    "        doc = nlp(str(line))\n",
    "        for token in doc:\n",
    "            tags.append((token.text, token.pos_, token.tag_, token.dep_, token.is_stop))\n",
    "        if len(tags) != 0:\n",
    "            POS_tag_dict[i] = tags\n",
    "    return POS_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "scenic-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_sentence(sentence):\n",
    "    #list of sentences\n",
    "    POS_tag_dict = dict()\n",
    "    text = sentence.split()\n",
    "    for line in text:\n",
    "        tags = []\n",
    "        doc = nlp(str(line))\n",
    "        for token in doc:\n",
    "            tags.append((token.pos_, token.tag_, token.dep_, token.is_stop, ))\n",
    "        if len(tags) != 0:\n",
    "            POS_tag_dict[token.text] = tags[0]\n",
    "    return POS_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "controlled-deviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': ('DET', 'DT', 'ROOT', True),\n",
       " 'Prisoner': ('PROPN', 'NNP', 'ROOT', False),\n",
       " 'of': ('ADP', 'IN', 'ROOT', True),\n",
       " 'Azkaban': ('ADJ', 'JJ', 'ROOT', False),\n",
       " 'made': ('VERB', 'VBD', 'ROOT', True),\n",
       " 'a': ('DET', 'DT', 'ROOT', True),\n",
       " 'total': ('ADJ', 'JJ', 'ROOT', False),\n",
       " '796.7': ('SYM', '$', 'nmod', False),\n",
       " 'million': ('NUM', 'CD', 'ROOT', False),\n",
       " 'worldwide': ('ADV', 'RB', 'ROOT', False)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence(sentence3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-joyce",
   "metadata": {},
   "source": [
    "# Dependency Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "burning-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Token dict \n",
    "def dependency_dict(doc):\n",
    "    out = dict()\n",
    "    root = ''\n",
    "    for token in doc:\n",
    "        out[token.text] = (token.dep_, token.head.text, token.head.pos_,[child for child in token.children])\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            root = token.text\n",
    "    return out, root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prerequisite-holly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Harry': ('compound', 'Potter', 'PROPN', []),\n",
       "  'Potter': ('nsubj', 'is', 'AUX', [Harry, and, Prisoner]),\n",
       "  'and': ('cc', 'directed', 'VERB', []),\n",
       "  'the': ('det', 'Prisoner', 'PROPN', []),\n",
       "  'Prisoner': ('conj', 'Potter', 'PROPN', [the, of]),\n",
       "  'of': ('prep', 'Prisoner', 'PROPN', [Azkaban]),\n",
       "  'Azkaban': ('pobj', 'of', 'ADP', []),\n",
       "  'is': ('ROOT', 'is', 'AUX', [Potter, film]),\n",
       "  'a': ('det', 'film', 'NOUN', []),\n",
       "  '2004': ('nummod', 'film', 'NOUN', []),\n",
       "  'fantasy': ('compound', 'film', 'NOUN', []),\n",
       "  'film': ('attr', 'is', 'AUX', [a, 2004, fantasy, directed]),\n",
       "  'directed': ('acl', 'film', 'NOUN', [by, and, distributed]),\n",
       "  'by': ('agent', 'distributed', 'VERB', [Bros.]),\n",
       "  'Alfonso': ('compound', 'Cuarón', 'PROPN', []),\n",
       "  'Cuarón': ('pobj', 'by', 'ADP', [Alfonso]),\n",
       "  'distributed': ('conj', 'directed', 'VERB', [by]),\n",
       "  'Warner': ('compound', 'Bros.', 'PROPN', []),\n",
       "  'Bros.': ('pobj', 'by', 'ADP', [Warner])},\n",
       " 'is')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_Dict1, root1 = dependency_dict(doc1)\n",
    "token_Dict1, root1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ongoing-grenada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Harry': ('compound', 'Potter', 'PROPN', []),\n",
       "  'Potter': ('nsubj', 'spending', 'VERB', [Harry]),\n",
       "  'has': ('aux', 'spending', 'VERB', []),\n",
       "  'been': ('aux', 'spending', 'VERB', []),\n",
       "  'spending': ('ROOT',\n",
       "   'spending',\n",
       "   'VERB',\n",
       "   [Potter, has, been, summer, with, .]),\n",
       "  'another': ('det', 'summer', 'NOUN', []),\n",
       "  'unhappy': ('amod', 'summer', 'NOUN', []),\n",
       "  'summer': ('dobj', 'spending', 'VERB', [another, unhappy]),\n",
       "  'with': ('prep', 'spending', 'VERB', [Dursleys]),\n",
       "  'the': ('det', 'Dursleys', 'PROPN', []),\n",
       "  'Dursleys': ('pobj', 'with', 'ADP', [the]),\n",
       "  '.': ('punct', 'spending', 'VERB', [])},\n",
       " 'spending')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_Dict2, root2 = dependency_dict(doc2)\n",
    "token_Dict2, root2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "classical-agent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'The': ('det', 'Prisoner', 'PROPN', []),\n",
       "  'Prisoner': ('nsubj', 'made', 'VERB', [The, of]),\n",
       "  'of': ('prep', 'total', 'NOUN', [million]),\n",
       "  'Azkaban': ('pobj', 'of', 'ADP', []),\n",
       "  'made': ('ROOT', 'made', 'VERB', [Prisoner, total, worldwide]),\n",
       "  'a': ('det', 'total', 'NOUN', []),\n",
       "  'total': ('dobj', 'made', 'VERB', [a, of]),\n",
       "  '$': ('quantmod', 'million', 'NUM', []),\n",
       "  '796.7': ('compound', 'million', 'NUM', []),\n",
       "  'million': ('pobj', 'of', 'ADP', [$, 796.7]),\n",
       "  'worldwide': ('advmod', 'made', 'VERB', [])},\n",
       " 'made')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_Dict3, root3 = dependency_dict(doc3)\n",
    "token_Dict3, root3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-twenty",
   "metadata": {},
   "source": [
    "# NER Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "clean-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_tag(text):\n",
    "    NER_tag_dict = dict()\n",
    "    for i,line in enumerate(text):\n",
    "        tags = []\n",
    "        doc = nlp(str(line))\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            # print(ent.text +'-' + ent.label_ + '\\n')\n",
    "            tags.append(ent.text +'-' + ent.label_)\n",
    "        if len(tags) != 0:\n",
    "            NER_tag_dict[i] = tags\n",
    "    return NER_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "collaborative-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_tag_sentence(sentence):\n",
    "    doc = nlp(str(sentence))\n",
    "    NER_tag_dict = dict()\n",
    "    tags = []\n",
    "    for ent in doc.ents:\n",
    "        # print(ent.text +'-' + ent.label_ + '\\n')\n",
    "        NER_tag_dict[ent.text] = ent.label_\n",
    "    return NER_tag_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-planning",
   "metadata": {},
   "source": [
    "# Binary Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "anonymous-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_verbs = [\"am\", \"is\", \"are\", \"was\", \"were\", \"shall\", \"do\", \"does\", \"did\",\"can\", \"could\", \"have\", \"need\", \"should\", \"will\", \"would\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prompt-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: a single sentence, with its dependency dict and root word\n",
    "def binaryQ(sentence, token_dict, root):\n",
    "    output = ''\n",
    "    if root in auxiliary_verbs:\n",
    "        output += root.capitalize() + ' '\n",
    "    for k in sentence.split():\n",
    "        if k != root:\n",
    "            output += k + ' '\n",
    "    output = output[:-2]+ '?'\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indie-disaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Harry Potter and the Prisoner of Azkaban a 2004 fantasy film directed by Alfonso Cuarón and distributed by Warner Bros?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryQ(sentence1, token_Dict1, root1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-rings",
   "metadata": {},
   "source": [
    "# Who Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "iraqi-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Harry': ('PROPN', 'NNP', 'ROOT', False),\n",
       " 'Potter': ('NOUN', 'NN', 'ROOT', False),\n",
       " 'has': ('VERB', 'VBZ', 'ROOT', True),\n",
       " 'been': ('VERB', 'VBN', 'ROOT', True),\n",
       " 'spending': ('VERB', 'VBG', 'ROOT', False),\n",
       " 'another': ('DET', 'DT', 'ROOT', True),\n",
       " 'unhappy': ('ADJ', 'JJ', 'ROOT', False),\n",
       " 'summer': ('NOUN', 'NN', 'ROOT', False),\n",
       " 'with': ('ADP', 'IN', 'ROOT', True),\n",
       " 'the': ('DET', 'DT', 'ROOT', True),\n",
       " '.': ('PROPN', 'NNP', 'ROOT', False)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_sentence(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "catholic-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tag_dict2 = ner_tag_sentence(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "billion-bracket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Harry': ('compound', 'Potter', 'PROPN', []),\n",
       "  'Potter': ('nsubj', 'spending', 'VERB', [Harry]),\n",
       "  'has': ('aux', 'spending', 'VERB', []),\n",
       "  'been': ('aux', 'spending', 'VERB', []),\n",
       "  'spending': ('ROOT',\n",
       "   'spending',\n",
       "   'VERB',\n",
       "   [Potter, has, been, summer, with, .]),\n",
       "  'another': ('det', 'summer', 'NOUN', []),\n",
       "  'unhappy': ('amod', 'summer', 'NOUN', []),\n",
       "  'summer': ('dobj', 'spending', 'VERB', [another, unhappy]),\n",
       "  'with': ('prep', 'spending', 'VERB', [Dursleys]),\n",
       "  'the': ('det', 'Dursleys', 'PROPN', []),\n",
       "  'Dursleys': ('pobj', 'with', 'ADP', [the]),\n",
       "  '.': ('punct', 'spending', 'VERB', [])},\n",
       " 'spending',\n",
       " {'Harry Potter': 'PERSON', 'summer': 'DATE', 'Dursleys': 'PERSON'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_dict2, root2 = dependency_dict(doc2)\n",
    "dependency_dict2, root2,ner_tag_dict2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "congressional-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: a single sentence, and its ner tag dict and dependency dict\n",
    "#Who Question\n",
    "def whoQ(sentence, ner_tag_dict, dependency_dict):\n",
    "    #find PERSON tag\n",
    "    theName = ''\n",
    "    output = ''\n",
    "    for k in ner_tag_dict.keys():\n",
    "        if ner_tag_dict[k] == 'PERSON':\n",
    "            #check if is a subject\n",
    "            names = k.split()\n",
    "            for n in names:\n",
    "                print(dependency_dict[n])\n",
    "                if dependency_dict[n][0] == 'nsubj':\n",
    "                    theName = k\n",
    "    print(theName)\n",
    "    output = sentence.replace(theName, 'who')\n",
    "    output = output[:-1] + \"?\"\n",
    "    output = output[0].upper() + output[1:]\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "democratic-transport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('compound', 'Potter', 'PROPN', [])\n",
      "('nsubj', 'spending', 'VERB', [Harry])\n",
      "('pobj', 'with', 'ADP', [the])\n",
      "Harry Potter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Who has been spending another unhappy summer with the Dursleys?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whoQ(sentence2, ner_tag_dict2, dependency_dict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-clone",
   "metadata": {},
   "source": [
    "# How much Question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "union-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tag_dict3 = ner_tag_sentence(sentence3)\n",
    "dependency_dict3, root3 = dependency_dict(doc3)\n",
    "pos_tag_dict3 = pos_tag_sentence(sentence3)\n",
    "# \"The film was produced by La Petite Reine and ARP Sélection for 13.47 million euros.\" don't identify as MONEY\n",
    "# \"The film was produced by La Petite Reine and ARP Sélection for 13.47 million dollars.\"\n",
    "    # How much was the film produced by La Petite Reine and ARP Sélection?\n",
    "# \"The film costs 13.47 million dollars.\"\n",
    "    # How much does the film costs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sacred-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tag_dict4 = ner_tag_sentence(sentence4)\n",
    "dependency_dict4, root4 = dependency_dict(doc4)\n",
    "pos_tag_dict4 = pos_tag_sentence(sentence4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fourth-invasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'$796.7 million': 'MONEY'},\n",
       " {'The': ('det', 'Prisoner', 'PROPN', []),\n",
       "  'Prisoner': ('nsubj', 'made', 'VERB', [The, of]),\n",
       "  'of': ('prep', 'total', 'NOUN', [million]),\n",
       "  'Azkaban': ('pobj', 'of', 'ADP', []),\n",
       "  'made': ('ROOT', 'made', 'VERB', [Prisoner, total, worldwide]),\n",
       "  'a': ('det', 'total', 'NOUN', []),\n",
       "  'total': ('dobj', 'made', 'VERB', [a, of]),\n",
       "  '$': ('quantmod', 'million', 'NUM', []),\n",
       "  '796.7': ('compound', 'million', 'NUM', []),\n",
       "  'million': ('pobj', 'of', 'ADP', [$, 796.7]),\n",
       "  'worldwide': ('advmod', 'made', 'VERB', [])},\n",
       " 'made',\n",
       " {'The': ('DET', 'DT', 'ROOT', True),\n",
       "  'Prisoner': ('PROPN', 'NNP', 'ROOT', False),\n",
       "  'of': ('ADP', 'IN', 'ROOT', True),\n",
       "  'Azkaban': ('ADJ', 'JJ', 'ROOT', False),\n",
       "  'made': ('VERB', 'VBD', 'ROOT', True),\n",
       "  'a': ('DET', 'DT', 'ROOT', True),\n",
       "  'total': ('ADJ', 'JJ', 'ROOT', False),\n",
       "  '796.7': ('SYM', '$', 'nmod', False),\n",
       "  'million': ('NUM', 'CD', 'ROOT', False),\n",
       "  'worldwide': ('ADV', 'RB', 'ROOT', False)})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag_dict3, dependency_dict3, root3, pos_tag_dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "further-squad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'13.47 million dollars': 'MONEY'},\n",
       " {'The': ('det', 'film', 'NOUN', []),\n",
       "  'film': ('nsubj', 'took', 'VERB', [The]),\n",
       "  'took': ('ROOT', 'took', 'VERB', [film, them, dollars, .]),\n",
       "  'them': ('dative', 'took', 'VERB', []),\n",
       "  '13.47': ('compound', 'million', 'NUM', []),\n",
       "  'million': ('nummod', 'dollars', 'NOUN', [13.47]),\n",
       "  'dollars': ('dobj', 'took', 'VERB', [million]),\n",
       "  '.': ('punct', 'took', 'VERB', [])},\n",
       " 'took',\n",
       " {'The': ('DET', 'DT', 'ROOT', True),\n",
       "  'film': ('NOUN', 'NN', 'ROOT', False),\n",
       "  'took': ('VERB', 'VBD', 'ROOT', False),\n",
       "  'them': ('PRON', 'PRP', 'ROOT', True),\n",
       "  '13.47': ('NUM', 'CD', 'ROOT', False),\n",
       "  'million': ('NUM', 'CD', 'ROOT', False),\n",
       "  '.': ('NOUN', 'NNS', 'ROOT', False)})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag_dict4, dependency_dict4, root4, pos_tag_dict4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-scottish",
   "metadata": {},
   "source": [
    "VB verb, base form take\n",
    "VBD verb, past tense took\n",
    "VBG verb, gerund/present participle taking\n",
    "VBN verb, past participle taken\n",
    "VBP verb, sing. present, non-3d take\n",
    "VBZ verb, 3rd person sing. present takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hired-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check tense of verb\n",
    "def check_tense(root, pos_dict):\n",
    "    tag = pos_dict[root][1]\n",
    "    if tag == \"VB\":\n",
    "        return \"do\"\n",
    "    elif tag == \"VBD\":\n",
    "        return \"did\"\n",
    "    elif tag == \"VBG\":\n",
    "        return \"doing\"\n",
    "    elif tag == \"VBN\":\n",
    "        return \"done\"\n",
    "    elif tag == \"VBP\":\n",
    "        return \"do\"\n",
    "    elif tag == \"VBZ\":\n",
    "        return \"does\"\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "technological-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: a single sentence, and its ner tag dict and dependency dict\n",
    "#How much Question\n",
    "#The film was produced by La Petite Reine and ARP Sélection for 13.47 million dollars.\n",
    "#How much was the film produced by La Petite Reine and ARP Sélection?\n",
    "def howMuchQ(sentence, doc, ner_tag_dict, dependency_dict, root, pos_dict):\n",
    "    theMoney = \"\"\n",
    "    output = \"\"\n",
    "    theSubj = \"\"\n",
    "    for k in ner_tag_dict.keys():\n",
    "        if ner_tag_dict[k] == 'MONEY':\n",
    "            theMoney = k\n",
    "    #check passive tense \n",
    "    sentence_lst = sentence.split()\n",
    "    root_ind = sentence_lst.index(root)\n",
    "    root_token = doc[root_ind]\n",
    "    if root_ind != 0:\n",
    "        word_in_front_of_root = sentence_lst[root_ind -1] \n",
    "        #if it's passive tense\n",
    "        if dependency_dict[word_in_front_of_root][0] == 'auxpass':\n",
    "            root_aux = word_in_front_of_root\n",
    "            output += 'How much '+ root_aux + ' '\n",
    "            for n in dependency_dict:\n",
    "                if dependency_dict[n][0] == 'nsubjpass':\n",
    "                    theSubj = n    \n",
    "            words_before_subj = dependency_dict[theSubj][-1]\n",
    "            if len(words_before_subj) != 0:\n",
    "                output += str(words_before_subj[0]).lower() + ' '\n",
    "            output += theSubj + \"?\"\n",
    "            \n",
    "        else: #if it's not passive tense\n",
    "            for n in dependency_dict:\n",
    "                if dependency_dict[n][0] == 'nsubj':\n",
    "                    theSubj = n  \n",
    "            output += 'How much '\n",
    "            #check tense\n",
    "            tense = check_tense(root, pos_dict)\n",
    "            if tense != None:\n",
    "                output += tense + ' '\n",
    "                #check subject\n",
    "                for i, n in enumerate(dependency_dict):\n",
    "                    if dependency_dict[n][0] == 'nsubj':\n",
    "                        theSubj = str(n)    \n",
    "\n",
    "                words_before_subj = dependency_dict[theSubj][-1]\n",
    "                if len(words_before_subj) != 0:\n",
    "                    for t in words_before_subj:\n",
    "                        output += str(t).lower() + \" \"\n",
    "                output += theSubj + ' ' + root_token.lemma_ + \"?\"\n",
    "            else:\n",
    "                return None\n",
    "    return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "delayed-methodology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much did the film take?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "howMuchQ(sentence4, doc4, ner_tag_dict4, dependency_dict4, root4, pos_tag_dict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cloudy-listing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much did the of Prisoner make?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "howMuchQ(sentence3, doc3, ner_tag_dict3, dependency_dict3, root3, pos_tag_dict3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-cover",
   "metadata": {},
   "source": [
    "# Why Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "loved-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify “because”, “since”, “for”, “due to”, “... result…”, “lead to”\n",
    "# NP VP because (of) something\n",
    "# Since ..., NP VP\n",
    "# NP VP for ... (reason)\n",
    "# NP result (in) NP\n",
    "# NP lead to NP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "knowing-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence5 = \"Oldman accepted the part because he needed the money\"\n",
    "doc5 = nlp(sentence5)\n",
    "ner_tag_dict5 = ner_tag_sentence(sentence5)\n",
    "dependency_dict5, root5 = dependency_dict(doc5)\n",
    "pos_tag_dict5 = pos_tag_sentence(sentence5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "static-source",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({},\n",
       " {'Oldman': ('nsubj', 'accepted', 'VERB', []),\n",
       "  'accepted': ('ROOT', 'accepted', 'VERB', [Oldman, part, needed]),\n",
       "  'the': ('det', 'money', 'NOUN', []),\n",
       "  'part': ('dobj', 'accepted', 'VERB', [the]),\n",
       "  'because': ('mark', 'needed', 'VERB', []),\n",
       "  'he': ('nsubj', 'needed', 'VERB', []),\n",
       "  'needed': ('advcl', 'accepted', 'VERB', [because, he, money]),\n",
       "  'money': ('dobj', 'needed', 'VERB', [the])},\n",
       " {'Oldman': ('PROPN', 'NNP', 'ROOT', False),\n",
       "  'accepted': ('VERB', 'VBD', 'ROOT', False),\n",
       "  'the': ('DET', 'DT', 'ROOT', True),\n",
       "  'part': ('NOUN', 'NN', 'ROOT', True),\n",
       "  'because': ('SCONJ', 'IN', 'ROOT', True),\n",
       "  'he': ('PRON', 'PRP', 'ROOT', True),\n",
       "  'needed': ('VERB', 'VBD', 'ROOT', False),\n",
       "  'money': ('NOUN', 'NN', 'ROOT', False)},\n",
       " 'accepted')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag_dict5, dependency_dict5, pos_tag_dict5, root5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "southern-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence6 = \"Only the first Quidditch game was kept in the film, due to its importance to the storyline.\"\n",
    "doc6 = nlp(sentence6)\n",
    "ner_tag_dict6 = ner_tag_sentence(sentence6)\n",
    "dependency_dict6, root6 = dependency_dict(doc6)\n",
    "pos_tag_dict6 = pos_tag_sentence(sentence6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "demonstrated-delay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'first': 'ORDINAL', 'Quidditch': 'NORP'},\n",
       " {'Only': ('advmod', 'game', 'NOUN', []),\n",
       "  'the': ('det', 'storyline', 'NOUN', []),\n",
       "  'first': ('amod', 'game', 'NOUN', []),\n",
       "  'Quidditch': ('compound', 'game', 'NOUN', []),\n",
       "  'game': ('nsubjpass', 'kept', 'VERB', [Only, the, first, Quidditch]),\n",
       "  'was': ('auxpass', 'kept', 'VERB', []),\n",
       "  'kept': ('ROOT', 'kept', 'VERB', [game, was, in, ,, due, .]),\n",
       "  'in': ('prep', 'kept', 'VERB', [film]),\n",
       "  'film': ('pobj', 'in', 'ADP', [the]),\n",
       "  ',': ('punct', 'kept', 'VERB', []),\n",
       "  'due': ('prep', 'kept', 'VERB', [to, importance]),\n",
       "  'to': ('prep', 'importance', 'NOUN', [storyline]),\n",
       "  'its': ('poss', 'importance', 'NOUN', []),\n",
       "  'importance': ('pobj', 'due', 'ADP', [its, to]),\n",
       "  'storyline': ('pobj', 'to', 'ADP', [the]),\n",
       "  '.': ('punct', 'kept', 'VERB', [])},\n",
       " {'Only': ('ADV', 'RB', 'ROOT', True),\n",
       "  'the': ('DET', 'DT', 'ROOT', True),\n",
       "  'first': ('ADV', 'RB', 'ROOT', True),\n",
       "  'Quidditch': ('PROPN', 'NNP', 'ROOT', False),\n",
       "  'game': ('NOUN', 'NN', 'ROOT', False),\n",
       "  'was': ('AUX', 'VBD', 'ROOT', True),\n",
       "  'kept': ('VERB', 'VBD', 'ROOT', False),\n",
       "  'in': ('ADP', 'IN', 'ROOT', True),\n",
       "  ',': ('NOUN', 'NN', 'ROOT', False),\n",
       "  'due': ('ADJ', 'JJ', 'ROOT', True),\n",
       "  'to': ('PART', 'TO', 'ROOT', True),\n",
       "  'its': ('PRON', 'PRP$', 'ROOT', True),\n",
       "  'importance': ('NOUN', 'NN', 'ROOT', False),\n",
       "  '.': ('PROPN', 'NNP', 'ROOT', False)},\n",
       " 'kept')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag_dict6, dependency_dict6, pos_tag_dict6, root6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "resident-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence7 = \"Censors initially gave it adult ratings due to profanity\"\n",
    "doc7 = nlp(sentence7)\n",
    "ner_tag_dict7 = ner_tag_sentence(sentence7)\n",
    "dependency_dict7, root7 = dependency_dict(doc7)\n",
    "pos_tag_dict7 = pos_tag_sentence(sentence7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "curious-study",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({},\n",
       " {'Censors': ('nsubj', 'gave', 'VERB', []),\n",
       "  'initially': ('advmod', 'gave', 'VERB', []),\n",
       "  'gave': ('ROOT', 'gave', 'VERB', [Censors, initially, it, ratings, due]),\n",
       "  'it': ('dative', 'gave', 'VERB', []),\n",
       "  'adult': ('compound', 'ratings', 'NOUN', []),\n",
       "  'ratings': ('dobj', 'gave', 'VERB', [adult]),\n",
       "  'due': ('prep', 'gave', 'VERB', [to, profanity]),\n",
       "  'to': ('pcomp', 'due', 'ADP', []),\n",
       "  'profanity': ('pobj', 'due', 'ADP', [])},\n",
       " {'Censors': ('NOUN', 'NNS', 'ROOT', False),\n",
       "  'initially': ('ADV', 'RB', 'ROOT', False),\n",
       "  'gave': ('VERB', 'VBD', 'ROOT', False),\n",
       "  'it': ('PRON', 'PRP', 'ROOT', True),\n",
       "  'adult': ('NOUN', 'NN', 'ROOT', False),\n",
       "  'ratings': ('NOUN', 'NNS', 'ROOT', False),\n",
       "  'due': ('ADJ', 'JJ', 'ROOT', True),\n",
       "  'to': ('PART', 'TO', 'ROOT', True),\n",
       "  'profanity': ('NOUN', 'NN', 'ROOT', False)},\n",
       " 'gave')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag_dict7, dependency_dict7, pos_tag_dict7, root7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "angry-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WhyQ(sentence, doc, ner_tag_dict, dependency_dict, pos_tag_dict, root):\n",
    "    #A do sth Because B\n",
    "    theSubj = \"\"\n",
    "    output = \"\"\n",
    "    theObj = \"\"\n",
    "    sentence_lst = sentence.split()\n",
    "    root_ind = sentence_lst.index(root)\n",
    "    #check tense\n",
    "    tense = check_tense(root, pos_tag_dict)\n",
    "    \n",
    "    \n",
    "    if \"because\" or \"due to\" or \"Due to\" in sentence:\n",
    "        #check if passive tense:\n",
    "        word_in_front_of_root = sentence_lst[root_ind-1]\n",
    "        if dependency_dict[word_in_front_of_root][0] == 'auxpass':\n",
    "            root_aux = word_in_front_of_root\n",
    "            for n in dependency_dict:\n",
    "                if dependency_dict[n][0] == 'nsubjpass': \n",
    "                    words_before_subj = dependency_dict[n][-1]\n",
    "                    if len(words_before_subj) != 0:\n",
    "                        for t in words_before_subj:\n",
    "                            if str(t) not in ner_tag_dict.keys():\n",
    "                                theSubj += str(t).lower() + ' '\n",
    "                            else:\n",
    "                                theSubj += str(t) + ' '\n",
    "                    theSubj += n + \" \"\n",
    "            output += \"Why \" + root_aux + \" \"+ theSubj + doc[root_ind].text + \"?\"\n",
    "\n",
    "        else:\n",
    "            #not passive tense:\n",
    "            #find subject\n",
    "            for n in dependency_dict:\n",
    "                if dependency_dict[n][0] == 'nsubj':\n",
    "                    #find determinant if there is one\n",
    "                    words_before_subj = dependency_dict[n][-1]\n",
    "                    if len(words_before_subj) != 0:\n",
    "                        for t in words_before_subj:\n",
    "                            theSubj += str(t) + ' '\n",
    "                    theSubj += n  \n",
    "                    break\n",
    "            #find object\n",
    "            for n in dependency_dict:\n",
    "                if dependency_dict[n][0] == 'dobj':\n",
    "                    #find determinant if there is one\n",
    "                    words_before_obj = dependency_dict[n][-1]\n",
    "                    if len(words_before_obj) != 0:\n",
    "                        for t in words_before_obj:\n",
    "                            theObj += str(t) + ' '\n",
    "                    theObj += n\n",
    "                    break\n",
    "\n",
    "            #check tense\n",
    "            tense = check_tense(root, pos_tag_dict)\n",
    "            #Get rid of things after because\n",
    "\n",
    "            #Why + do/does/did sb do sth?\n",
    "            output += \"Why \" + tense + \" \" + theSubj +  \" \" + doc[root_ind].lemma_ + \" \" + theObj + \"?\"\n",
    "    return output\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "hearing-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did Oldman accept the part?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WhyQ(sentence5, doc5, ner_tag_dict5, dependency_dict5, pos_tag_dict5, root5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fundamental-quebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why was only the first Quidditch game kept?'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WhyQ(sentence6, doc6, ner_tag_dict6, dependency_dict6, pos_tag_dict6, root6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "filled-auckland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kept'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "musical-desert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did Censors give adult ratings?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WhyQ(sentence7, doc7, ner_tag_dict7, dependency_dict7, pos_tag_dict7, root7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-craps",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-drinking",
   "metadata": {},
   "source": [
    "sentence1 = \"Harry Potter and the Prisoner of Azkaban is a 2004 fantasy film directed by Alfonso Cuarón and distributed by Warner Bros.\"\n",
    "sentence2 = \"Harry Potter has been spending another unhappy summer with the Dursleys.\"\n",
    "sentence3 = \"The film was produced by La Petite Reine and ARP Sélection for 13.47 million dollars.\"\n",
    "sentence4 = \"The film took them 13.47 million dollars.\"\n",
    "\n",
    "question4 = \"How much did the film take?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "protected-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bert sentence embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "sensitive-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question1 = \"How much did the film take?\"\n",
    "question2 = 'Is Harry Potter and the Prisoner of Azkaban a 2004 fantasy film directed by Alfonso Cuarón and distributed by Warner Bros?'\n",
    "\n",
    "question1_emb = np.array(sbert_model.encode(question1)).reshape(1, -1)\n",
    "question2_emb = np.array(sbert_model.encode(question2)).reshape(1, -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "occupied-liver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop words (?), contains cardinal numbers\n",
    "all_stopwords = nlp.Defaults.stop_words\n",
    "len(all_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-locator",
   "metadata": {},
   "source": [
    "## Turn the entire text into sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "alike-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: text file \n",
    "#output: a dictionary of sentence embeddings {sentence: sentence embeddings}\n",
    "\n",
    "def sentence_emb(text):\n",
    "    result = dict()\n",
    "    for sentence in text:\n",
    "        sentence_emb = np.array(sbert_model.encode(sentence)).reshape(1, -1)\n",
    "        result[sentence] = sentence_emb\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "liable-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_artist_emb, text_hp_emb = sentence_emb(text_artist), sentence_emb(text_hp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "renewable-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_sentence(question, text_emb_dict):\n",
    "    question_emb = np.array(sbert_model.encode(question)).reshape(1, -1)\n",
    "    sim_max = 0\n",
    "    output = \"\"\n",
    "    for sentence, sentence_emb in text_emb_dict.items():\n",
    "        sim = cosine_similarity(sentence_emb, question_emb)\n",
    "        if sim > sim_max:\n",
    "            sim_max = sim\n",
    "            output = sentence\n",
    "    return output, sim_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "front-orchestra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 2, 1]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 5, 3]\n",
    "sorted(a)[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "creative-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Question type\n",
    "question_types = [\"Who\", \"When\", \"What\" , \"Where\",\" How many\", \"How long\", \"How much\", \"Why\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "functional-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_question_type(question):\n",
    "    #Check Question type\n",
    "    for q_type in question_types:\n",
    "        if question.startswith(q_type):\n",
    "            return q_type\n",
    "    for a_verb in auxiliary_verbs:\n",
    "        a_verb = a_verb[0].upper() + a_verb[1:]\n",
    "        if question.startswith(a_verb):\n",
    "            return a_verb\n",
    "    return \"No idea\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "established-seventh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Is', 'How much')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_question_type(question2), check_question_type(question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "numeric-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find sentence with question type as an argument\n",
    "def find_best_k_sentence(question, text_emb_dict, k, question_type):\n",
    "    question_emb = np.array(sbert_model.encode(question)).reshape(1, -1)\n",
    "    sims_dict = dict()\n",
    "    output = \"\"\n",
    "    for sentence, sentence_emb in text_emb_dict.items():\n",
    "        sim = cosine_similarity(sentence_emb, question_emb)\n",
    "        if check_NER(sentence, question_type):\n",
    "            sim += 1\n",
    "        sims_dict[sentence] = sim\n",
    "    sorted_sim = sorted(sims_dict.items(), key = lambda kv: kv[1])[::-1][:k]\n",
    "    return sorted_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cardiac-wagon",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-52-554e8ad007e2>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-554e8ad007e2>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    if\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#check if the sentence contains certain NER tags\n",
    "#When - date\n",
    "#Who - Person\n",
    "#Where\",\n",
    "#\"How many\"\n",
    "#\"How long\"\n",
    "#\"How much\"\n",
    "#\"Why\"\n",
    "\n",
    "\n",
    "def check_NER(sentence, question_type):\n",
    "    output = False\n",
    "    ner_tag_dict = ner_tag_sentence(sentence)\n",
    "    if question_type == \"when\":\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1, sim_max1 = find_best_sentence(question1, text_artist_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1, sim_max1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2, sim_max2 = find_best_sentence(question2, text_hp_emb)\n",
    "output2, sim_max2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_k_sentence(question1, text_artist_emb, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "related-store",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-e021ec700bdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output2' is not defined"
     ]
    }
   ],
   "source": [
    "output2, question2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-remains",
   "metadata": {},
   "source": [
    "# Binary Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary Questions\n",
    "#Strip the punctuation at the end\n",
    "#input: question and original sentence in text\n",
    "#check : 1) negation words: no/not/'nt √ \n",
    "#        2) Adjectives -> check antonymn\n",
    "#        3) Check Info matching?\n",
    "\n",
    "def binary_answer(question, sentence):\n",
    "    negate = False\n",
    "    output = \"\"\n",
    "    neg_words = {'no', 'not', \"don't\", \"doesn't\", \"did't\", \"haven't\", \"hasn't\", \"wasn't\", \"weren't\"}\n",
    "    sentence_set = set([x.lower() for x in sentence.split()])\n",
    "    question_set = set([x.lower() for x in question[:-1].split()])\n",
    "    intersect_words = sentence_set.intersection(question_set)\n",
    "    leftover_question = question_set - intersect_words\n",
    "    leftover_sentence = sentence_set - intersect_words\n",
    "    print(\"leftover words: \")\n",
    "    print(leftover_question, leftover_question)\n",
    "    \n",
    "    negate = not check_negate(leftover_question, leftover_question)\n",
    "    if negate:\n",
    "        #No\n",
    "        output += \"No. \" + sentence\n",
    "    else:\n",
    "        #Yes\n",
    "        output += \"Yes. \" + sentence\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neg_words = ['no', 'not',\"n't\"]\n",
    "#return true if same\n",
    "def check_negate(set1, set2):\n",
    "    print(\"hi\")\n",
    "    negate1, negate2 = True, True\n",
    "    print(\"Negate\", negate1, negate2)\n",
    "    if len(set1) == 0 and len(set2) == 0:\n",
    "        return negate1 and negate2\n",
    "    for item1 in set1:\n",
    "        if (item1 == 'no') or (item1 == 'not') or (\"n't\" in item1):\n",
    "            negate1 = not negate1\n",
    "#             print(\"1\", item1)\n",
    "\n",
    "    for item2 in set2:\n",
    "        if (item2 == 'no') or (item2 == 'not') or (\"n't\" in item2):\n",
    "            negate2 = not negate2\n",
    "#             print(\"2\", item2)\n",
    "    print(\"Negate\", negate1 and negate2)\n",
    "            \n",
    "    return negate1 and negate2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set([\"nose\", \"not\", \"hi\", \"won't\"])\n",
    "set2 = set([\"n\", \"hi\", \"won't\"])\n",
    "check_negate(set1, set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_answer(question2, output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-shape",
   "metadata": {},
   "source": [
    "# HOW MUCH Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_howmuch = \"How much did The Prisoner of Azkaban make worldwide?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_k_sentence(question_howmuch, text_hp_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, sim_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    ancestors = [t.text for t in token.ancestors]\n",
    "    children = [t.text for t in token.children]\n",
    "    print(token.text, \"\\t\", token.i, \"\\t\", \n",
    "          token.pos_, \"\\t\", token.dep_, \"\\t\", \n",
    "          ancestors, \"\\t\", children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-apollo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-savage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
